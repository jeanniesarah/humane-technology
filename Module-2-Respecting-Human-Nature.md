### **Module 2 | Respecting Human Nature** (completed)

We'll take a candid look at how technology can support and protect the human vulnerabilities and biases that we have evolved with.

How can technology work in harmony with the vulnerabilities and biases with which all humans have evolved?

It’s impossible to give a deep-dive into cognitive science, neuroscience, social psychology, and all their intersections with technology in this short course. But learning more about them will undoubtedly help you build more humane products.

Instead of competing to know more machine learning frameworks, compete to know more about protecting human vulnerabilities. Moreover, since you will not be able to understand and account for all of these factors, your technologies should be capable of:

- Receiving information from users about their experience
- Learning how your technology does or doesn't support user values
- Evolving towards increasing alignment between platform design and user well-being

**Key Takeaways**:

- Human biases and vulnerabilities are inherent and hardwired. They have evolved to help us survive in an ancient environment, not our modern one.

- These evolutionary tendencies are now being exploited by technology.

- We believe too much in our own abilities while believing too little in how we can be manipulated, influenced, and shaped.

- What we perceive to be true depends on the context in which we see it.
- It’s important that we begin to see products in terms of human vulnerabilities.
- Just because we look at something, or we click on something, that doesn’t mean it’s what we want, or even what we believe is best for us.
- To “give people what they want” is often an easy way to avoid moral responsibility for exploiting human desire and a poor strategy for making people happy in the long term.
- Humane technologists build products that respect rather than exploit the complexities of human nature.
- Instead of assuming intent based on what users reveal via their engagement metrics, focus on understanding users’ values and goals, and help them refine their moment-to-moment intentions.

**Resources:**

- Human-Design-Guide-Worksheet.pdf

- To see a visual map of more than 188 cognitive biases, check out the [Cognitive Bias Codex](https://www.designhacks.co/products/cognitive-bias-codex-poster) and [Cognitive Bias Cheat Sheet](https://medium.com/better-humans/cognitive-bias-cheat-sheet-55a472476b18), by Buster Benson.

- Interested in understanding more about social media and its influence on the brain? Visit CHT’s [How Social Media Hacks our Brains](https://www.humanetech.com/brain-science) page.

- To explore neurodiversity and its impact on the design of software systems, check out this [short and well-cited view](https://journalofethics.ama-assn.org/article/myth-normal-brain-embracing-neurodiversity/2015-04) on how there’s no such thing as a “normal” mind.
- Learn more about [Dark Patterns](https://www.darkpatterns.org/) that trick us into behavior that we didn’t intend.
- Addictive design patterns are also covered in Center for Humane Technology’s podcast _Your Undivided Attention_: [What Happened in Vegas](https://www.humanetech.com/podcast/1-what-happened-in-vegas) and [Should’ve Stayed in Vegas](https://www.humanetech.com/podcast/2-shouldve-stayed-in-vegas)​

**Books:**

- To explore how new stimuli are processed and either ignored or put in context, check out [_Thinking, Fast and Slow_](https://www.goodreads.com/book/show/11468377-thinking-fast-and-slow), by Daniel Kahneman.
- To explore how human minds and values interact with machine learning systems, check out [_The Alignment Problem_](https://brianchristian.org/the-alignment-problem/), by Brian Christian.
