### **Module 4 | Centering Values**

We’ll explore the extent to which technology shapes our world, and reflect on the conditions and values that have shaped each of our journeys in life.

_How do the conditions of our lives shape our values? How might product development be informed by metrics but centered on values?_

#### Introduction

The larger and more profitable a technology company is, the greater the cost of taking responsibility for the harms of its products, so these companies often create arguments of technological neutrality to justify their behavior. The reality is that technology is not, and can never be, neutral.

1. The conditions that shape technology, including our own values
2. How all choices humans make are expressions of their values
3. The role of metrics in the myth of neutrality
4. How values must guide humane technology

> “The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it is intended to monitor.” - Donald Campbell, Psychologist and Social Scientist

While metrics are useful for managing scale, their initially apparent objectivity is often confused for ethical neutrality. In reality, metrics have deep impact on the behavior of social systems—and not always in desirable ways:

- Machine learning systems optimize for metrics and cannot know when complex values are being violated.
- An individual’s psycho-metric profile is a distorted image, not their “true self.”
- It’s hard—and sometimes impossible—to quantify things that matter. _It’s easy to measure usage, connections, numbers of clicks, and other engagement numbers. But how easy is it to measure fulfillment? Deep relationships? Meaning?_
- Clicks are not an accurate measure of desire or preference. Often, clicks measure what humans can’t help but interact with as opposed to their true intentions.
- What we measure becomes what we value: engagement metrics become human connection, revenue becomes social value

**Humane technologists don't confuse what's easily measurable with what matters. Ask yourself what game your product encourages people to play, and whether it's what you actually intended.**

Taking a humanely oriented, complex systems perspective requires us to be “epistemically humble” and to accept the inherent uncertainty of living in a world in which everything is subject to change:

- Self
- Society
- Organizations
- Products
- Goals and values

Rather than thinking of these as fixed, static entities to be controlled through complicated mechanisms, consider them as fluid, complex processes constantly shaped by shifting conditions. Your role as a humane technologist is to support this evolution.

**Designing social systems at scale inherently involves difficult prioritization—so the question to ask is: what values do we want our products to enable in the world?**

#### Understanding Values

In order to support the values of all stakeholders (such as the company, the community, and the ecology), technologists must learn how to engage in “values inquiry”: asking fundamental questions and rigorously reasoning about values like truth, goodness, and justice.

- How do you know what you or another person values?
- What are your organization's values? What about the other stakeholders affected by your technology?
- Where are there tensions between values? What can you do when facing disagreement?

One measure of success in design is the degree to which your technology can integrate a wide range of deep values. This requires curiosity and effort to understand the experiences and reasoning that lead to the choices of people we are unfamiliar with (an important topic of the upcoming modules).

​Consider this list of values created by the BBC for use in design: https://www.bbc.co.uk/rd/projects/digital-wellbeing

#### Identify Your System's Purpose

> “The best way to deduce [a] system’s purpose is to watch for a while and to see how the system behaves.

If a frog turns right and catches a fly, and then turns left and catches a fly, and then turns around backward and catches a fly, the purpose of the frog has to do not with turning left or right or backward, but with catching flies.

If a government proclaims its interest in protecting the environment but allocates little money or effort toward that goal, environmental protection is not, in fact, the government’s purpose.

Purposes are deduced from behavior, not from rhetoric or stated goals.”

- Donella Meadows, Author of The Limits to Growth

Don’t assume you know how your product is working or that the goals and intentions you’ve set are playing out as you wish. Don’t convince yourself that your metrics are an accurate picture of those intentions. _Be metrics-informed but values-driven_, **recognizing that metrics are only one of several imperfect tools to inform decision-making in a complex environment.**

You can be values-driven and metrics-informed:
**Get committed to the “why” of your feature or product.** Recognize that values require sacrifice, and that the sacrifice is worth it. Staying true to your values may mean sacrificing other forms of success and could create friction with customers, investors, or other stakeholders. But taking the time to explore your values and align around them as a team will drive inspiration, alignment, and ultimately, trust within your team and from your users.

**Don’t let simple metrics define what’s most important.** A humane technology will prioritize a constellation of values like overall well-being over a simplified metric like engagement. This would include metrics like surveys of self-reported life satisfaction, as well as multidisciplinary approaches. These could include qualitative, open-ended feedback from users, asking them:

- What do you feel like before, after, and while using this product?
- How does it affect your relationships, health, and sense of self?
- How does it help you live up to your highest self?

Utilizing this data could be supported by advances in NLP but also rely on disciplinary experts outside of STEM such as philosophers, anthropologists, and psychologists.

Learning and decision-making may become more complex, but this is necessary to match the complexity of the system you want to positively influence.

#### Shift What You're Optimizing

**Optimizing the parts doesn't always lead to optimization of the whole, especially in complex systems.** As David Stroh wrote in Systems Thinking for Social Change, “in order to optimize the performance of the entire system, people need to **shift from trying to optimize their part of the system to improving relationships among its constituent parts.**”

In this case, the “whole” is _how a technology impacts the user and their wider community_. The “parts” are _individual elements of the technology such as specific algorithms, features, and metrics._ Technology teams must move in and out, from parts to whole and whole to parts, so that they can grow in their understanding of the technology's effect on individual users and communities.

This process is often underappreciated and under-resourced. Ask yourself where you could switch your focus to these types of relationships. This may entail expanding your role to be more cross-functional, or hiring a new person to take on that role. These types of jobs are not common, often because their contributions are not conveniently captured by simple metrics.

#### Be Genuinely Trustworthy

To be truly trustworthy, it’s not enough to just know your values. Trustworthy institutions and technologies consist of several factors:

- **Integrity**: your intentions and motivations align with your stated values.

- **Competency**: you are actually capable of accomplishing, or learning how to accomplish, your stated goals.

- **Accountability**: fulfilling integrity and competency must be tied to supporting the well-being of your stakeholders.

- **Education**: you create clear paths that allow those dependent on you to increase their understanding, gradually bridging asymmetries of power and knowledge over time.

**To build trust, humane product teams have clear strategies for maintaining integrity with their values, continuously developing the competency to live up to those values, and caring for (and ideally, educating) their users.**

_Try This Litmus Test: Would you be willing to get up and defend an important product decision to the stakeholders most negatively impacted by it? If you were one of those stakeholders, would you trust the people who made that decision?_

Behaving in a trustworthy manner is often incompatible with traditional definitions of “success” in extractive markets. Success that sacrifices values for metrics and public trust for profit is destructive and unstable.

Genuine trustworthiness provides a different path: where values, not markets, define success; where a culture of values alignment attracts talent; where governments and NGOs are partners rather than adversaries.

Humane technology requires that we forge a new path—values are how we find it.

#### Key Takeaways

- Our own values and assumptions are encoded in the products we build and the choices our products present to others.
- Society’s values shape how a technology is used and the impact that it has, regardless of the inventor's intentions.
- Every interaction a person has, whether with people or products, changes them.
- Every one of us has a set of underlying conditions: values, hopes, beliefs, characteristics, and assumptions that come from socialization, education, and other experiences.
- We need to stay rooted in our deepest values so that we can identify and fight for those values when they’re not upheld.
- Be metrics-informed but values-driven, recognizing that metrics are only one of several imperfect tools to inform decision-making in a complex environment.

  - It’s hard to quantify things that matter.
  - An individual’s psycho-metric profile is a distorted image, not their “true self.”
  - Clicks are not an accurate measure of desire or preference.
  - What we measure becomes what we value.
  - Machine learning systems optimize for metrics and cannot know when complex values are being violated.

- **Designing social systems at scale inherently involves difficult prioritization—so the question to ask is: what values do we want our products to enable in the world?**

#### Resources

To explore the idea of values in product design, explore Value Sensitive Design by Batya Friedman and David G. Hendry.

​Check out The School for Social Design Textbook https://vbsd.super.site/ from Time Well Spent co-founder Joe Edelman, which uses your own work as a case study to learn how to design better social systems.

To understand the values of the people using your product check out the 14 Core Values Framework, a set of resources for assessing and designing around user values.
